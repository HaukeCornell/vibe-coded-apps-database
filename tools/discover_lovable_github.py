#!/usr/bin/env python3
"""
GitHub Lovable Repository Discovery

Searches GitHub for repositories created with Lovable platform using:
- Lovable bot commits
- README patterns mentioning Lovable
- Repository descriptions with Lovable references
"""

import requests
import json
import time
import logging
from datetime import datetime
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LovableGitHubDiscovery:
    def __init__(self, github_token=None):
        """Initialize GitHub search for Lovable repositories."""
        self.github_token = github_token or os.getenv('GITHUB_TOKEN')
        if not self.github_token:
            logger.warning("No GitHub token provided - limited to 60 requests/hour")
        
        self.headers = {
            'Accept': 'application/vnd.github.v3+json',
            'User-Agent': 'Vibe-Coded-Apps-Database/1.0'
        }
        
        if self.github_token:
            self.headers['Authorization'] = f'token {self.github_token}'
        
        self.base_url = 'https://api.github.com/search'
    
    def search_repositories(self, query, sort='updated', order='desc', per_page=100, max_results=1000):
        """Search GitHub repositories with the given query."""
        results = []
        page = 1
        
        while len(results) < max_results:
            try:
                params = {
                    'q': query,
                    'sort': sort,
                    'order': order,
                    'per_page': min(per_page, 100),
                    'page': page
                }
                
                response = requests.get(f"{self.base_url}/repositories", headers=self.headers, params=params)
                
                if response.status_code == 403:
                    logger.warning("Rate limit hit. Waiting 60 seconds...")
                    time.sleep(60)
                    continue
                
                if response.status_code != 200:
                    logger.error(f"Search failed: {response.status_code} - {response.text}")
                    break
                
                data = response.json()
                items = data.get('items', [])
                
                if not items:
                    break
                
                results.extend(items)
                logger.info(f"Found {len(items)} repositories (page {page}, total: {len(results)})")
                
                # GitHub search API limits to 1000 results
                if len(results) >= data.get('total_count', 0) or len(results) >= 1000:
                    break
                
                page += 1
                time.sleep(1)  # Rate limiting
                
            except Exception as e:
                logger.error(f"Error searching repositories: {e}")
                break
        
        return results[:max_results]
    
    def search_lovable_patterns(self):
        """Search for various Lovable-related patterns."""
        search_patterns = [
            # README content patterns
            '"Built with Lovable" in:readme',
            'lovable.app in:readme',
            '"Lovable AI" in:readme',
            '"lovable.dev" in:readme',
            
            # Repository description patterns  
            '"Built with Lovable" in:description',
            'lovable.app in:description',
            
            # File content patterns
            'filename:README.md "Lovable"',
            'filename:package.json "lovable"',
            
            # Specific patterns from known Lovable repos
            '"This is a Lovable project" in:readme',
            '"Generated by Lovable" in:readme'
        ]
        
        all_results = {}
        
        for pattern in search_patterns:
            logger.info(f"üîç Searching: {pattern}")
            try:
                results = self.search_repositories(pattern, max_results=100)
                all_results[pattern] = results
                logger.info(f"‚úÖ Found {len(results)} repositories for pattern: {pattern}")
                
                # Show sample results
                if results:
                    sample = results[0]
                    logger.info(f"üìã Sample: {sample['full_name']} - {sample.get('description', 'No description')}")
                
                time.sleep(2)  # Rate limiting between searches
                
            except Exception as e:
                logger.error(f"‚ùå Error with pattern '{pattern}': {e}")
                all_results[pattern] = []
        
        return all_results
    
    def search_by_commits(self):
        """Search for repositories with Lovable bot commits."""
        logger.info("üîç Searching for Lovable bot commits...")
        
        # Note: GitHub doesn't allow searching by commit author in repository search
        # This would require a different approach using the commits API
        commit_patterns = [
            'author:lovable-ai',
            'committer:lovable-ai', 
            'author-email:noreply@lovable.dev',
            'committer-email:noreply@lovable.dev'
        ]
        
        results = {}
        for pattern in commit_patterns:
            logger.info(f"üìù Commit search pattern: {pattern}")
            # This would require using the commits search API or GraphQL
            results[pattern] = "Requires commits API - not repository search"
        
        return results
    
    def analyze_repository(self, repo_data):
        """Analyze a repository to determine if it's Lovable-generated."""
        analysis = {
            'repo_name': repo_data['full_name'],
            'description': repo_data.get('description', ''),
            'created_at': repo_data['created_at'],
            'updated_at': repo_data['updated_at'],
            'language': repo_data.get('language'),
            'stars': repo_data['stargazers_count'],
            'is_likely_lovable': False,
            'confidence_indicators': []
        }
        
        # Check description for Lovable indicators
        description = (repo_data.get('description') or '').lower()
        lovable_keywords = ['lovable', 'lovable.app', 'lovable.dev', 'ai-generated']
        
        for keyword in lovable_keywords:
            if keyword in description:
                analysis['confidence_indicators'].append(f"Description contains '{keyword}'")
                analysis['is_likely_lovable'] = True
        
        # Check repository name patterns
        name = repo_data['name'].lower()
        if any(pattern in name for pattern in ['lovable', 'ai-gen', 'generated']):
            analysis['confidence_indicators'].append("Repository name suggests AI generation")
            analysis['is_likely_lovable'] = True
        
        return analysis
    
    def run_discovery(self):
        """Run complete Lovable repository discovery."""
        logger.info("üöÄ Starting Lovable GitHub repository discovery...")
        
        # Search for repositories with Lovable patterns
        search_results = self.search_lovable_patterns()
        
        # Search for commit patterns (informational)
        commit_info = self.search_by_commits()
        
        # Deduplicate and analyze results
        unique_repos = {}
        total_found = 0
        
        for pattern, repos in search_results.items():
            for repo in repos:
                repo_id = repo['id']
                if repo_id not in unique_repos:
                    unique_repos[repo_id] = repo
                    total_found += 1
        
        logger.info(f"üìä Total unique repositories found: {len(unique_repos)}")
        
        # Analyze repositories for Lovable indicators
        analyzed_repos = []
        for repo in unique_repos.values():
            analysis = self.analyze_repository(repo)
            analyzed_repos.append(analysis)
        
        # Filter for likely Lovable repositories
        likely_lovable = [repo for repo in analyzed_repos if repo['is_likely_lovable']]
        logger.info(f"üéØ Likely Lovable repositories: {len(likely_lovable)}")
        
        # Save results
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"lovable_github_discovery_{timestamp}.json"
        
        discovery_data = {
            'timestamp': datetime.now().isoformat(),
            'search_patterns': list(search_results.keys()),
            'total_repositories_found': len(unique_repos),
            'likely_lovable_count': len(likely_lovable),
            'search_results': search_results,
            'commit_search_info': commit_info,
            'analyzed_repositories': analyzed_repos,
            'likely_lovable_repositories': likely_lovable
        }
        
        with open(output_file, 'w') as f:
            json.dump(discovery_data, f, indent=2)
        
        logger.info(f"üíæ Discovery results saved to {output_file}")
        
        # Log summary
        if likely_lovable:
            logger.info("üî• Top Lovable repository candidates:")
            for i, repo in enumerate(likely_lovable[:5], 1):
                logger.info(f"  {i}. {repo['repo_name']} - {repo['description']}")
                logger.info(f"     Indicators: {', '.join(repo['confidence_indicators'])}")
        
        return discovery_data

def main():
    """Main discovery function."""
    github_token = os.getenv('GITHUB_TOKEN')
    if not github_token:
        logger.warning("No GITHUB_TOKEN environment variable found!")
        logger.warning("Set with: export GITHUB_TOKEN='your_token'")
        logger.info("Proceeding with limited rate limits...")
    
    discoverer = LovableGitHubDiscovery(github_token)
    results = discoverer.run_discovery()
    
    logger.info("üéâ Lovable GitHub discovery completed!")

if __name__ == "__main__":
    main()